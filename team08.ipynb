{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"team08.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FaWaYXG1fIRm","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn\n","import torch.optim\n","import torchvision.datasets\n","import torchvision.transforms\n","import torch.utils.data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GA4Aiz2Giu5e","colab_type":"code","colab":{}},"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyK3i7pS9gSH","colab_type":"text"},"source":["# Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"-Vf3xEV29k0y","colab_type":"text"},"source":["## Module definition\n","\n","Our autoencoder will be defined by the `ConvolutionalAutoencoder` class which uses a `ConvolutionalEncoder` object to encode followed a `ConvolutionalDecoder` object to decode. The `ConvolutionalEncoder` and `ConvolutionalDecoder` classes make use of `n_blocks` `ConvolutionalBlock`s or `DeconvolutionalBlock`s which are composed of `layer_per_block` convolution layers with the same number of filters.\n","\n","The dimensionality is reduced by applying 2-factor spatial downsampling at each block. The number of filters is doubled for each subsequent block. The decoder makes the exact oposite process.\n","\n","The final layer uses a tanh activation."]},{"cell_type":"code","metadata":{"id":"z6ZgDF0kfIRy","colab_type":"code","colab":{}},"source":["class ConvolutionalAutoencoder(torch.nn.Module):\n","\n","    def __init__(self, n_blocks, downsampling_method, upsampling_method,\n","                 layers_per_block=2):\n","        super().__init__()\n","        self.n_blocks = n_blocks\n","        self.downsampling_method = downsampling_method\n","        self.upsampling_method = upsampling_method\n","\n","        self.encoder = ConvolutionalEncoder(n_blocks, downsampling_method,\n","                                            layers_per_block=layers_per_block)\n","        self.decoder = ConvolutionalDecoder(n_blocks, upsampling_method,\n","                                            self.encoder.output_channels,\n","                                            layers_per_block)\n","\n","    def forward(self, x):\n","        code = self.encoder(x)\n","        reconstruction = self.decoder(code)\n","        return reconstruction\n","\n","\n","class ConvolutionalEncoder(torch.nn.Module):\n","\n","    DOWNSAMPLING_METHODS = [\"max-pooling\", \"avg-pooling\", \"stride-2\"]\n","\n","    def __init__(self, n_blocks, downsampling_method, init_filters=16,\n","                 layers_per_block=2, kernel_size=5, input_channels=1):\n","        super().__init__()\n","        self.n_blocks = n_blocks\n","        assert downsampling_method in self.DOWNSAMPLING_METHODS\n","        self.downsampling_method = downsampling_method\n","        self.layers_per_block = layers_per_block\n","        self.init_filters = init_filters\n","        self.kernel_size = kernel_size\n","        self.input_channels = input_channels\n","\n","        layers = []\n","\n","        # First layer so we have <init_filters> channels.\n","        n_filters = init_filters\n","        layers.append(\n","            ConvolutionalBlock(input_channels, n_filters, kernel_size, 1))\n","\n","        # Encoding blocks.\n","        input_channels = n_filters\n","        for _ in range(n_blocks):\n","            if downsampling_method == \"max-pooling\":\n","                # Convolutional block + max pooling.\n","                conv_block = torch.nn.Sequential(\n","                    ConvolutionalBlock(input_channels, n_filters, kernel_size, layers_per_block),\n","                    torch.nn.MaxPool2d(2)\n","                )\n","            elif downsampling_method == \"avg-pooling\":\n","                # Convolutional block + average pooling.\n","                conv_block = torch.nn.Sequential(\n","                    ConvolutionalBlock(input_channels, n_filters, kernel_size, layers_per_block),\n","                    torch.nn.AvgPool2d(2)\n","                )\n","            else:\n","                # Stride-2 convolution.\n","                conv_block = ConvolutionalBlock(input_channels, n_filters,\n","                                                kernel_size,\n","                                                layers_per_block,\n","                                                last_stride=2)\n","            layers.append(conv_block)\n","            # Double the number of filters.\n","            input_channels = n_filters\n","            n_filters = 2 * n_filters\n","\n","        self.encoder = torch.nn.Sequential(*layers)\n","        self.output_channels = input_channels\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","\n","class ConvolutionalDecoder(torch.nn.Module):\n","\n","    UPSAMPLING_METHODS = [\"transposed\", \"bilinear\", \"bicubic\", \"nearest\"]\n","\n","    def __init__(self, n_blocks, upsampling_method, input_channels,\n","                 layers_per_block=2, kernel_size=5, output_channels=1):\n","        super().__init__()\n","        self.n_blocks = n_blocks\n","        assert upsampling_method in self.UPSAMPLING_METHODS\n","        self.upsampling_method = upsampling_method\n","        self.layers_per_block = layers_per_block\n","        self.input_channels = input_channels\n","        self.kernel_size = kernel_size\n","        self.output_channels = output_channels\n","\n","        layers = []\n","\n","        # Decoding blocks.\n","        n_filters = input_channels\n","        for _ in range(n_blocks):\n","            if upsampling_method == \"transposed\":\n","                # Deconvolutional block\n","                conv_block = DeconvolutionalBlock(input_channels, n_filters,\n","                                                  kernel_size, layers_per_block,\n","                                                  stride=2)\n","            else:\n","                # Upsampling.\n","                conv_block = torch.nn.Sequential(\n","                    ConvolutionalBlock(input_channels, n_filters, kernel_size,\n","                                       layers_per_block),\n","                    torch.nn.Upsample(scale_factor=2, mode=upsampling_method)\n","                )\n","            layers.append(conv_block)\n","            # Half the number of filters.\n","            input_channels = n_filters\n","            n_filters = n_filters // 2\n","\n","        # Last layer so we have <output_channels> channel.\n","        layers.append(torch.nn.Conv2d(input_channels, output_channels, kernel_size,\n","                                      padding=kernel_size // 2))\n","        layers.append(torch.nn.Tanh())\n","\n","        self.decoder = torch.nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.decoder(x)\n","\n","\n","class ConvolutionalBlock(torch.nn.Module):\n","    \"\"\"\n","\n","    Applies n_layers convolutional layers with the same number of\n","    filters (n_filters) and filter sizes (kerne_size) with ReLU activations\n","    keeping the same spacial size.\n","    \"\"\"\n","\n","    def __init__(self, input_channels, n_filters, kernel_size, n_layers,\n","                 last_stride=1):\n","        super().__init__()\n","        layers = []\n","        padding = kernel_size // 2  # To keep the same size.\n","\n","        for i in range(n_layers):\n","            if i == 0:  # First layer with correct input channels.\n","                layers.append(torch.nn.Conv2d(input_channels, n_filters,\n","                                              kernel_size, padding=padding))\n","            elif 0 < i < n_layers:  # Intermediate layers.\n","                layers.append(torch.nn.Conv2d(n_filters, n_filters,\n","                                              kernel_size, padding=padding))\n","            else:  # Last layer with stride.\n","                layers.append(torch.nn.Conv2d(n_filters, n_filters,\n","                                              kernel_size, last_stride, padding))\n","            layers.append(torch.nn.ReLU())\n","\n","        # To sequentially apply the layers.\n","        self.block = torch.nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","\n","class DeconvolutionalBlock(torch.nn.Module):\n","    \"\"\"\n","\n","    Applies a transposed convolution followed by n_layers-1 convolutional\n","    layers with the same number of filters and filter sizes with ReLU\n","    activations keeping the same spacial size.\n","    \"\"\"\n","\n","    def __init__(self, input_channels, n_filters, kernel_size, n_layers, stride):\n","        super().__init__()\n","        layers = []\n","        padding = kernel_size // 2\n","\n","        # Transposed convolution layer.\n","        layers.append(torch.nn.ConvTranspose2d(input_channels, n_filters,\n","                                               kernel_size, stride, padding))\n","        layers.append(torch.nn.ReLU())\n","\n","        for _ in range(n_layers - 1):\n","            layers.append(torch.nn.Conv2d(n_filters, n_filters, kernel_size,\n","                                          padding=padding))\n","            layers.append(torch.nn.ReLU())\n","\n","        # To sequentially apply the layers.\n","        self.block = torch.nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.block(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_ZD0rgWBhJa","colab_type":"text"},"source":["To do a quick test, we will pass a random image and check if the output is of the same size as the input."]},{"cell_type":"code","metadata":{"id":"hIO0AZWCfIR2","colab_type":"code","colab":{}},"source":["image = torch.randn((1, 1, 128, 128))\n","autoencoder = ConvolutionalAutoencoder(2, 'max-pooling', 'nearest').to(device)\n","output = autoencoder(image.to(device))\n","assert output.shape == (1, 1, 128, 128)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z25DsijeCNvi","colab_type":"text"},"source":["## Dataset\n","\n","We split the training set and normalize the input images."]},{"cell_type":"code","metadata":{"id":"ObQndlPufIR9","colab_type":"code","colab":{}},"source":["transform = torchvision.transforms.Compose([\n","     torchvision.transforms.ToTensor(),\n","     torchvision.transforms.Normalize((0.1307,), (0.3081,))  # Mean and std from internet...\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VIGvzG4fISD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"3bc1ae58-6e5f-4a3f-8e2e-f678fba722af","executionInfo":{"status":"ok","timestamp":1575228638843,"user_tz":-60,"elapsed":11325,"user":{"displayName":"Sergio Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64","userId":"16139820604268433723"}}},"source":["mnist = torchvision.datasets.MNIST('mnist_dataset', train=True, transform=transform, download=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:01, 8589457.60it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting mnist_dataset/MNIST/raw/train-images-idx3-ubyte.gz to mnist_dataset/MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 130374.85it/s]           \n","  0%|          | 0/1648877 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting mnist_dataset/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_dataset/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 2132143.04it/s]                            \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting mnist_dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_dataset/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 49428.94it/s]            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting mnist_dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_dataset/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K5cYwBL2fISH","colab_type":"code","colab":{}},"source":["dataset_len = len(mnist)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPrTXSnZfISN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba7c85c7-53ff-466f-bb4b-d85a18921b84","executionInfo":{"status":"ok","timestamp":1575228639813,"user_tz":-60,"elapsed":12282,"user":{"displayName":"Sergio Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64","userId":"16139820604268433723"}}},"source":["dataset_len * 0.95"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57000.0"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"B1BwFJY_fISU","colab_type":"code","colab":{}},"source":["mnist_train, mnist_val = torch.utils.data.random_split(mnist, [57000, dataset_len - 57000])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5yH0O1kfISY","colab_type":"code","colab":{}},"source":["train_dataloader = torch.utils.data.DataLoader(mnist_train,\n","                                               batch_size=32,\n","                                               shuffle=True,\n","                                               num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNNQ25Z-fISe","colab_type":"code","colab":{}},"source":["mse = torch.nn.MSELoss()\n","adam = torch.optim.Adam(autoencoder.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEwsot_KfISi","colab_type":"code","colab":{}},"source":["def train(model, dataloader, criterion, optimizer, epoch):\n","    for i, batch in enumerate(dataloader):\n","        images = batch[0].to(device)\n","        optimizer.zero_grad()\n","        reconstructed = model(images)\n","        loss = criterion(reconstructed, images)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if i % 100 == 0:\n","            print('[%d, %d] loss: %.3f' %\n","                  (epoch + 1, i + 1, loss.item()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXQlTiq2fISm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4c8762a1-882e-4092-ae1d-d01a899bc9c0","executionInfo":{"status":"ok","timestamp":1575228794730,"user_tz":-60,"elapsed":91626,"user":{"displayName":"Sergio Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64","userId":"16139820604268433723"}}},"source":["for epoch in range(5):\n","    train(autoencoder, train_dataloader, mse, adam, epoch)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[1, 1] loss: 0.983\n","[1, 101] loss: 0.427\n","[1, 201] loss: 0.407\n","[1, 301] loss: 0.395\n","[1, 401] loss: 0.335\n","[1, 501] loss: 0.355\n","[1, 601] loss: 0.328\n","[1, 701] loss: 0.346\n","[1, 801] loss: 0.340\n","[1, 901] loss: 0.354\n","[1, 1001] loss: 0.312\n","[1, 1101] loss: 0.274\n","[1, 1201] loss: 0.334\n","[1, 1301] loss: 0.343\n","[1, 1401] loss: 0.295\n","[1, 1501] loss: 0.372\n","[1, 1601] loss: 0.355\n","[1, 1701] loss: 0.320\n","[2, 1] loss: 0.333\n","[2, 101] loss: 0.340\n","[2, 201] loss: 0.318\n","[2, 301] loss: 0.312\n","[2, 401] loss: 0.320\n","[2, 501] loss: 0.353\n","[2, 601] loss: 0.317\n","[2, 701] loss: 0.347\n","[2, 801] loss: 0.318\n","[2, 901] loss: 0.325\n","[2, 1001] loss: 0.327\n","[2, 1101] loss: 0.364\n","[2, 1201] loss: 0.336\n","[2, 1301] loss: 0.341\n","[2, 1401] loss: 0.330\n","[2, 1501] loss: 0.342\n","[2, 1601] loss: 0.327\n","[2, 1701] loss: 0.331\n","[3, 1] loss: 0.349\n","[3, 101] loss: 0.316\n","[3, 201] loss: 0.283\n","[3, 301] loss: 0.345\n","[3, 401] loss: 0.341\n","[3, 501] loss: 0.324\n","[3, 601] loss: 0.316\n","[3, 701] loss: 0.329\n","[3, 801] loss: 0.324\n","[3, 901] loss: 0.347\n","[3, 1001] loss: 0.334\n","[3, 1101] loss: 0.314\n","[3, 1201] loss: 0.324\n","[3, 1301] loss: 0.306\n","[3, 1401] loss: 0.358\n","[3, 1501] loss: 0.312\n","[3, 1601] loss: 0.288\n","[3, 1701] loss: 0.342\n","[4, 1] loss: 0.368\n","[4, 101] loss: 0.311\n","[4, 201] loss: 0.334\n","[4, 301] loss: 0.365\n","[4, 401] loss: 0.344\n","[4, 501] loss: 0.302\n","[4, 601] loss: 0.279\n","[4, 701] loss: 0.371\n","[4, 801] loss: 0.341\n","[4, 901] loss: 0.329\n","[4, 1001] loss: 0.327\n","[4, 1101] loss: 0.288\n","[4, 1201] loss: 0.331\n","[4, 1301] loss: 0.332\n","[4, 1401] loss: 0.355\n","[4, 1501] loss: 0.324\n","[4, 1601] loss: 0.329\n","[4, 1701] loss: 0.310\n","[5, 1] loss: 0.277\n","[5, 101] loss: 0.281\n","[5, 201] loss: 0.345\n","[5, 301] loss: 0.312\n","[5, 401] loss: 0.307\n","[5, 501] loss: 0.318\n","[5, 601] loss: 0.329\n","[5, 701] loss: 0.341\n","[5, 801] loss: 0.308\n","[5, 901] loss: 0.358\n","[5, 1001] loss: 0.326\n","[5, 1101] loss: 0.345\n","[5, 1201] loss: 0.313\n","[5, 1301] loss: 0.320\n","[5, 1401] loss: 0.297\n","[5, 1501] loss: 0.350\n","[5, 1601] loss: 0.311\n","[5, 1701] loss: 0.322\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3OKrrQKRfISs","colab_type":"code","colab":{}},"source":["mnist_test = torchvision.datasets.MNIST('mnist_dataset', train=False, transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQh4_KZ8h5Aj","colab_type":"code","colab":{}},"source":["reconstructed = autoencoder(mnist_test[0][0].to(device).unsqueeze(0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmq0GFneiCDo","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZnZDQXqiGgv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":218},"outputId":"6ad1ca25-3c71-4b48-b64f-e49ded890343","executionInfo":{"status":"ok","timestamp":1575228917871,"user_tz":-60,"elapsed":1131,"user":{"displayName":"Sergio Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64","userId":"16139820604268433723"}}},"source":["plt.subplot(121)\n","plt.imshow(mnist_test[0][0][0], cmap='gray')\n","plt.subplot(122)\n","plt.imshow(reconstructed[0][0].detach().cpu().numpy(), cmap='gray')"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f2e80133588>"]},"metadata":{"tags":[]},"execution_count":20},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAC4CAYAAAD61bdSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niaKAA0CiKOAAkCgKOAAkigIOAIn6f5DZbWzKC9svAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"pyEnlw7JiJ-X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
