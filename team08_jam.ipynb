{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "name": "team08.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "FaWaYXG1fIRm",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms\n",
    "import torch.utils.data"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GA4Aiz2Giu5e",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyK3i7pS9gSH",
    "colab_type": "text"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Vf3xEV29k0y",
    "colab_type": "text"
   },
   "source": [
    "## Module definition\n",
    "\n",
    "Our autoencoder will be defined by the `ConvolutionalAutoencoder` class which uses a `ConvolutionalEncoder` object to encode followed a `ConvolutionalDecoder` object to decode. The `ConvolutionalEncoder` and `ConvolutionalDecoder` classes make use of `n_blocks` `ConvolutionalBlock`s or `DeconvolutionalBlock`s which are composed of `layer_per_block` convolution layers with the same number of filters.\n",
    "\n",
    "The dimensionality is reduced by applying 2-factor spatial downsampling at each block. The number of filters is doubled for each subsequent block. The decoder makes the exact oposite process.\n",
    "\n",
    "The final layer uses a tanh activation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z6ZgDF0kfIRy",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "class ConvolutionalAutoencoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_blocks, downsampling_method, upsampling_method,\n",
    "                 layers_per_block=2):\n",
    "        super().__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        self.downsampling_method = downsampling_method\n",
    "        self.upsampling_method = upsampling_method\n",
    "\n",
    "        self.encoder = ConvolutionalEncoder(n_blocks, downsampling_method,\n",
    "                                            layers_per_block=layers_per_block)\n",
    "        self.decoder = ConvolutionalDecoder(n_blocks, upsampling_method,\n",
    "                                            self.encoder.output_channels,\n",
    "                                            layers_per_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        code = self.encoder(x)\n",
    "        reconstruction = self.decoder(code)\n",
    "        return reconstruction\n",
    "\n",
    "\n",
    "class ConvolutionalEncoder(torch.nn.Module):\n",
    "\n",
    "    DOWNSAMPLING_METHODS = [\"max-pooling\", \"avg-pooling\", \"stride-2\"]\n",
    "\n",
    "    def __init__(self, n_blocks, downsampling_method, init_filters=16,\n",
    "                 layers_per_block=2, kernel_size=5, input_channels=1):\n",
    "        super().__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        assert downsampling_method in self.DOWNSAMPLING_METHODS\n",
    "        self.downsampling_method = downsampling_method\n",
    "        self.layers_per_block = layers_per_block\n",
    "        self.init_filters = init_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # First layer so we have <init_filters> channels.\n",
    "        n_filters = init_filters\n",
    "        layers.append(\n",
    "            ConvolutionalBlock(input_channels, n_filters, kernel_size, 1))\n",
    "\n",
    "        # Encoding blocks.\n",
    "        input_channels = n_filters\n",
    "        for _ in range(n_blocks):\n",
    "            if downsampling_method == \"max-pooling\":\n",
    "                # Convolutional block + max pooling.\n",
    "                conv_block = torch.nn.Sequential(\n",
    "                    ConvolutionalBlock(input_channels, n_filters, kernel_size, layers_per_block),\n",
    "                    torch.nn.MaxPool2d(2)\n",
    "                )\n",
    "            elif downsampling_method == \"avg-pooling\":\n",
    "                # Convolutional block + average pooling.\n",
    "                conv_block = torch.nn.Sequential(\n",
    "                    ConvolutionalBlock(input_channels, n_filters, kernel_size, layers_per_block),\n",
    "                    torch.nn.AvgPool2d(2)\n",
    "                )\n",
    "            else:\n",
    "                # Stride-2 convolution.\n",
    "                conv_block = ConvolutionalBlock(input_channels, n_filters,\n",
    "                                                kernel_size,\n",
    "                                                layers_per_block,\n",
    "                                                last_stride=2)\n",
    "            layers.append(conv_block)\n",
    "            # Double the number of filters.\n",
    "            input_channels = n_filters\n",
    "            n_filters = 2 * n_filters\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(*layers)\n",
    "        self.output_channels = input_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class ConvolutionalDecoder(torch.nn.Module):\n",
    "\n",
    "    UPSAMPLING_METHODS = [\"transposed\", \"bilinear\", \"bicubic\", \"nearest\"]\n",
    "\n",
    "    def __init__(self, n_blocks, upsampling_method, input_channels,\n",
    "                 layers_per_block=2, kernel_size=5, output_channels=1):\n",
    "        super().__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        assert upsampling_method in self.UPSAMPLING_METHODS\n",
    "        self.upsampling_method = upsampling_method\n",
    "        self.layers_per_block = layers_per_block\n",
    "        self.input_channels = input_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Decoding blocks.\n",
    "        n_filters = input_channels\n",
    "        for _ in range(n_blocks):\n",
    "            if upsampling_method == \"transposed\":\n",
    "                # Deconvolutional block\n",
    "                conv_block = DeconvolutionalBlock(input_channels, n_filters,\n",
    "                                                  kernel_size, layers_per_block,\n",
    "                                                  stride=2)\n",
    "            else:\n",
    "                # Upsampling.\n",
    "                conv_block = torch.nn.Sequential(\n",
    "                    ConvolutionalBlock(input_channels, n_filters, kernel_size,\n",
    "                                       layers_per_block),\n",
    "                    torch.nn.Upsample(scale_factor=2, mode=upsampling_method)\n",
    "                )\n",
    "            layers.append(conv_block)\n",
    "            # Half the number of filters.\n",
    "            input_channels = n_filters\n",
    "            n_filters = n_filters // 2\n",
    "\n",
    "        # Last layer so we have <output_channels> channel.\n",
    "        layers.append(torch.nn.Conv2d(input_channels, output_channels, kernel_size,\n",
    "                                      padding=kernel_size // 2))\n",
    "        layers.append(torch.nn.Tanh())\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "class ConvolutionalBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Applies n_layers convolutional layers with the same number of\n",
    "    filters (n_filters) and filter sizes (kerne_size) with ReLU activations\n",
    "    keeping the same spacial size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, n_filters, kernel_size, n_layers,\n",
    "                 last_stride=1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        padding = kernel_size // 2  # To keep the same size.\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            if i == 0:  # First layer with correct input channels.\n",
    "                layers.append(torch.nn.Conv2d(input_channels, n_filters,\n",
    "                                              kernel_size, padding=padding))\n",
    "            elif 0 < i < n_layers:  # Intermediate layers.\n",
    "                layers.append(torch.nn.Conv2d(n_filters, n_filters,\n",
    "                                              kernel_size, padding=padding))\n",
    "            else:  # Last layer with stride.\n",
    "                layers.append(torch.nn.Conv2d(n_filters, n_filters,\n",
    "                                              kernel_size, last_stride, padding))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # To sequentially apply the layers.\n",
    "        self.block = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class DeconvolutionalBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Applies a transposed convolution followed by n_layers-1 convolutional\n",
    "    layers with the same number of filters and filter sizes with ReLU\n",
    "    activations keeping the same spacial size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, n_filters, kernel_size, n_layers, stride):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        # Transposed convolution layer.\n",
    "        layers.append(torch.nn.ConvTranspose2d(input_channels, n_filters,\n",
    "                                               kernel_size, stride, padding))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(torch.nn.Conv2d(n_filters, n_filters, kernel_size,\n",
    "                                          padding=padding))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # To sequentially apply the layers.\n",
    "        self.block = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_ZD0rgWBhJa",
    "colab_type": "text"
   },
   "source": [
    "To do a quick test, we will pass a random image and check if the output is of the same size as the input."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hIO0AZWCfIR2",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "image = torch.randn((1, 1, 128, 128))\n",
    "autoencoder = ConvolutionalAutoencoder(2, 'max-pooling', 'nearest').to(device)\n",
    "output = autoencoder(image.to(device))\n",
    "assert output.shape == (1, 1, 128, 128)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z25DsijeCNvi",
    "colab_type": "text"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We split the training set and normalize the input images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ObQndlPufIR9",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.1307,), (0.3081,))  # Mean and std from internet...\n",
    "])"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1VIGvzG4fISD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "outputId": "3bc1ae58-6e5f-4a3f-8e2e-f678fba722af",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1575228638843,
     "user_tz": -60,
     "elapsed": 11325,
     "user": {
      "displayName": "Sergio Garcia",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64",
      "userId": "16139820604268433723"
     }
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "mnist = torchvision.datasets.MNIST('mnist_dataset', train=True, transform=transform, download=True)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_dataset\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting mnist_dataset\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_dataset\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_dataset\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_dataset\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_dataset\\MNIST\\raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_dataset\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_dataset\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_dataset\\MNIST\\raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_dataset\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting mnist_dataset\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_dataset\\MNIST\\raw\nProcessing...\n",
      "Done!\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "\r0.0%",
      "\r0.1%",
      "\r0.2%",
      "\r0.2%",
      "\r0.3%",
      "\r0.4%",
      "\r0.5%",
      "\r0.6%",
      "\r0.7%",
      "\r0.7%",
      "\r0.8%",
      "\r0.9%",
      "\r1.0%",
      "\r1.1%",
      "\r1.2%",
      "\r1.2%",
      "\r1.3%",
      "\r1.4%",
      "\r1.5%",
      "\r1.6%",
      "\r1.7%",
      "\r1.7%",
      "\r1.8%",
      "\r1.9%",
      "\r2.0%",
      "\r2.1%",
      "\r2.1%",
      "\r2.2%",
      "\r2.3%",
      "\r2.4%",
      "\r2.5%",
      "\r2.6%",
      "\r2.6%",
      "\r2.7%",
      "\r2.8%",
      "\r2.9%",
      "\r3.0%",
      "\r3.1%",
      "\r3.1%",
      "\r3.2%",
      "\r3.3%",
      "\r3.4%",
      "\r3.5%",
      "\r3.6%",
      "\r3.6%",
      "\r3.7%",
      "\r3.8%",
      "\r3.9%",
      "\r4.0%",
      "\r4.0%",
      "\r4.1%",
      "\r4.2%",
      "\r4.3%",
      "\r4.4%",
      "\r4.5%",
      "\r4.5%",
      "\r4.6%",
      "\r4.7%",
      "\r4.8%",
      "\r4.9%",
      "\r5.0%",
      "\r5.0%",
      "\r5.1%",
      "\r5.2%",
      "\r5.3%",
      "\r5.4%",
      "\r5.5%",
      "\r5.5%",
      "\r5.6%",
      "\r5.7%",
      "\r5.8%",
      "\r5.9%",
      "\r6.0%",
      "\r6.0%",
      "\r6.1%",
      "\r6.2%",
      "\r6.3%",
      "\r6.4%",
      "\r6.4%",
      "\r6.5%",
      "\r6.6%",
      "\r6.7%",
      "\r6.8%",
      "\r6.9%",
      "\r6.9%",
      "\r7.0%",
      "\r7.1%",
      "\r7.2%",
      "\r7.3%",
      "\r7.4%",
      "\r7.4%",
      "\r7.5%",
      "\r7.6%",
      "\r7.7%",
      "\r7.8%",
      "\r7.9%",
      "\r7.9%",
      "\r8.0%",
      "\r8.1%",
      "\r8.2%",
      "\r8.3%",
      "\r8.3%",
      "\r8.4%",
      "\r8.5%",
      "\r8.6%",
      "\r8.7%",
      "\r8.8%",
      "\r8.8%",
      "\r8.9%",
      "\r9.0%",
      "\r9.1%",
      "\r9.2%",
      "\r9.3%",
      "\r9.3%",
      "\r9.4%",
      "\r9.5%",
      "\r9.6%",
      "\r9.7%",
      "\r9.8%",
      "\r9.8%",
      "\r9.9%",
      "\r10.0%",
      "\r10.1%",
      "\r10.2%",
      "\r10.2%",
      "\r10.3%",
      "\r10.4%",
      "\r10.5%",
      "\r10.6%",
      "\r10.7%",
      "\r10.7%",
      "\r10.8%",
      "\r10.9%",
      "\r11.0%",
      "\r11.1%",
      "\r11.2%",
      "\r11.2%",
      "\r11.3%",
      "\r11.4%",
      "\r11.5%",
      "\r11.6%",
      "\r11.7%",
      "\r11.7%",
      "\r11.8%",
      "\r11.9%",
      "\r12.0%",
      "\r12.1%",
      "\r12.1%",
      "\r12.2%",
      "\r12.3%",
      "\r12.4%",
      "\r12.5%",
      "\r12.6%",
      "\r12.6%",
      "\r12.7%",
      "\r12.8%",
      "\r12.9%",
      "\r13.0%",
      "\r13.1%",
      "\r13.1%",
      "\r13.2%",
      "\r13.3%",
      "\r13.4%",
      "\r13.5%",
      "\r13.6%",
      "\r13.6%",
      "\r13.7%",
      "\r13.8%",
      "\r13.9%",
      "\r14.0%",
      "\r14.0%",
      "\r14.1%",
      "\r14.2%",
      "\r14.3%",
      "\r14.4%",
      "\r14.5%",
      "\r14.5%",
      "\r14.6%",
      "\r14.7%",
      "\r14.8%",
      "\r14.9%",
      "\r15.0%",
      "\r15.0%",
      "\r15.1%",
      "\r15.2%",
      "\r15.3%",
      "\r15.4%",
      "\r15.5%",
      "\r15.5%",
      "\r15.6%",
      "\r15.7%",
      "\r15.8%",
      "\r15.9%",
      "\r16.0%",
      "\r16.0%",
      "\r16.1%",
      "\r16.2%",
      "\r16.3%",
      "\r16.4%",
      "\r16.4%",
      "\r16.5%",
      "\r16.6%",
      "\r16.7%",
      "\r16.8%",
      "\r16.9%",
      "\r16.9%",
      "\r17.0%",
      "\r17.1%",
      "\r17.2%",
      "\r17.3%",
      "\r17.4%",
      "\r17.4%",
      "\r17.5%",
      "\r17.6%",
      "\r17.7%",
      "\r17.8%",
      "\r17.9%",
      "\r17.9%",
      "\r18.0%",
      "\r18.1%",
      "\r18.2%",
      "\r18.3%",
      "\r18.3%",
      "\r18.4%",
      "\r18.5%",
      "\r18.6%",
      "\r18.7%",
      "\r18.8%",
      "\r18.8%",
      "\r18.9%",
      "\r19.0%",
      "\r19.1%",
      "\r19.2%",
      "\r19.3%",
      "\r19.3%",
      "\r19.4%",
      "\r19.5%",
      "\r19.6%",
      "\r19.7%",
      "\r19.8%",
      "\r19.8%",
      "\r19.9%",
      "\r20.0%",
      "\r20.1%",
      "\r20.2%",
      "\r20.2%",
      "\r20.3%",
      "\r20.4%",
      "\r20.5%",
      "\r20.6%",
      "\r20.7%",
      "\r20.7%",
      "\r20.8%",
      "\r20.9%",
      "\r21.0%",
      "\r21.1%",
      "\r21.2%",
      "\r21.2%",
      "\r21.3%",
      "\r21.4%",
      "\r21.5%",
      "\r21.6%",
      "\r21.7%",
      "\r21.7%",
      "\r21.8%",
      "\r21.9%",
      "\r22.0%",
      "\r22.1%",
      "\r22.1%",
      "\r22.2%",
      "\r22.3%",
      "\r22.4%",
      "\r22.5%",
      "\r22.6%",
      "\r22.6%",
      "\r22.7%",
      "\r22.8%",
      "\r22.9%",
      "\r23.0%",
      "\r23.1%",
      "\r23.1%",
      "\r23.2%",
      "\r23.3%",
      "\r23.4%",
      "\r23.5%",
      "\r23.6%",
      "\r23.6%",
      "\r23.7%",
      "\r23.8%",
      "\r23.9%",
      "\r24.0%",
      "\r24.0%",
      "\r24.1%",
      "\r24.2%",
      "\r24.3%",
      "\r24.4%",
      "\r24.5%",
      "\r24.5%",
      "\r24.6%",
      "\r24.7%",
      "\r24.8%",
      "\r24.9%",
      "\r25.0%",
      "\r25.0%",
      "\r25.1%",
      "\r25.2%",
      "\r25.3%",
      "\r25.4%",
      "\r25.5%",
      "\r25.5%",
      "\r25.6%",
      "\r25.7%",
      "\r25.8%",
      "\r25.9%",
      "\r26.0%",
      "\r26.0%",
      "\r26.1%",
      "\r26.2%",
      "\r26.3%",
      "\r26.4%",
      "\r26.4%",
      "\r26.5%",
      "\r26.6%",
      "\r26.7%",
      "\r26.8%",
      "\r26.9%",
      "\r26.9%",
      "\r27.0%",
      "\r27.1%",
      "\r27.2%",
      "\r27.3%",
      "\r27.4%",
      "\r27.4%",
      "\r27.5%",
      "\r27.6%",
      "\r27.7%",
      "\r27.8%",
      "\r27.9%",
      "\r27.9%",
      "\r28.0%",
      "\r28.1%",
      "\r28.2%",
      "\r28.3%",
      "\r28.3%",
      "\r28.4%",
      "\r28.5%",
      "\r28.6%",
      "\r28.7%",
      "\r28.8%",
      "\r28.8%",
      "\r28.9%",
      "\r29.0%",
      "\r29.1%",
      "\r29.2%",
      "\r29.3%",
      "\r29.3%",
      "\r29.4%",
      "\r29.5%",
      "\r29.6%",
      "\r29.7%",
      "\r29.8%",
      "\r29.8%",
      "\r29.9%",
      "\r30.0%",
      "\r30.1%",
      "\r30.2%",
      "\r30.2%",
      "\r30.3%",
      "\r30.4%",
      "\r30.5%",
      "\r30.6%",
      "\r30.7%",
      "\r30.7%",
      "\r30.8%",
      "\r30.9%",
      "\r31.0%",
      "\r31.1%",
      "\r31.2%",
      "\r31.2%",
      "\r31.3%",
      "\r31.4%",
      "\r31.5%",
      "\r31.6%",
      "\r31.7%",
      "\r31.7%",
      "\r31.8%",
      "\r31.9%",
      "\r32.0%",
      "\r32.1%",
      "\r32.1%",
      "\r32.2%",
      "\r32.3%",
      "\r32.4%",
      "\r32.5%",
      "\r32.6%",
      "\r32.6%",
      "\r32.7%",
      "\r32.8%",
      "\r32.9%",
      "\r33.0%",
      "\r33.1%",
      "\r33.1%",
      "\r33.2%",
      "\r33.3%",
      "\r33.4%",
      "\r33.5%",
      "\r33.6%",
      "\r33.6%",
      "\r33.7%",
      "\r33.8%",
      "\r33.9%",
      "\r34.0%",
      "\r34.0%",
      "\r34.1%",
      "\r34.2%",
      "\r34.3%",
      "\r34.4%",
      "\r34.5%",
      "\r34.5%",
      "\r34.6%",
      "\r34.7%",
      "\r34.8%",
      "\r34.9%",
      "\r35.0%",
      "\r35.0%",
      "\r35.1%",
      "\r35.2%",
      "\r35.3%",
      "\r35.4%",
      "\r35.5%",
      "\r35.5%",
      "\r35.6%",
      "\r35.7%",
      "\r35.8%",
      "\r35.9%",
      "\r36.0%",
      "\r36.0%",
      "\r36.1%",
      "\r36.2%",
      "\r36.3%",
      "\r36.4%",
      "\r36.4%",
      "\r36.5%",
      "\r36.6%",
      "\r36.7%",
      "\r36.8%",
      "\r36.9%",
      "\r36.9%",
      "\r37.0%",
      "\r37.1%",
      "\r37.2%",
      "\r37.3%",
      "\r37.4%",
      "\r37.4%",
      "\r37.5%",
      "\r37.6%",
      "\r37.7%",
      "\r37.8%",
      "\r37.9%",
      "\r37.9%",
      "\r38.0%",
      "\r38.1%",
      "\r38.2%",
      "\r38.3%",
      "\r38.3%",
      "\r38.4%",
      "\r38.5%",
      "\r38.6%",
      "\r38.7%",
      "\r38.8%",
      "\r38.8%",
      "\r38.9%",
      "\r39.0%",
      "\r39.1%",
      "\r39.2%",
      "\r39.3%",
      "\r39.3%",
      "\r39.4%",
      "\r39.5%",
      "\r39.6%",
      "\r39.7%",
      "\r39.8%",
      "\r39.8%",
      "\r39.9%",
      "\r40.0%",
      "\r40.1%",
      "\r40.2%",
      "\r40.2%",
      "\r40.3%",
      "\r40.4%",
      "\r40.5%",
      "\r40.6%",
      "\r40.7%",
      "\r40.7%",
      "\r40.8%",
      "\r40.9%",
      "\r41.0%",
      "\r41.1%",
      "\r41.2%",
      "\r41.2%",
      "\r41.3%",
      "\r41.4%",
      "\r41.5%",
      "\r41.6%",
      "\r41.7%",
      "\r41.7%",
      "\r41.8%",
      "\r41.9%",
      "\r42.0%",
      "\r42.1%",
      "\r42.1%",
      "\r42.2%",
      "\r42.3%",
      "\r42.4%",
      "\r42.5%",
      "\r42.6%",
      "\r42.6%",
      "\r42.7%",
      "\r42.8%",
      "\r42.9%",
      "\r43.0%",
      "\r43.1%",
      "\r43.1%",
      "\r43.2%",
      "\r43.3%",
      "\r43.4%",
      "\r43.5%",
      "\r43.6%",
      "\r43.6%",
      "\r43.7%",
      "\r43.8%",
      "\r43.9%",
      "\r44.0%",
      "\r44.0%",
      "\r44.1%",
      "\r44.2%",
      "\r44.3%",
      "\r44.4%",
      "\r44.5%",
      "\r44.5%",
      "\r44.6%",
      "\r44.7%",
      "\r44.8%",
      "\r44.9%",
      "\r45.0%",
      "\r45.0%",
      "\r45.1%",
      "\r45.2%",
      "\r45.3%",
      "\r45.4%",
      "\r45.5%",
      "\r45.5%",
      "\r45.6%",
      "\r45.7%",
      "\r45.8%",
      "\r45.9%",
      "\r45.9%",
      "\r46.0%",
      "\r46.1%",
      "\r46.2%",
      "\r46.3%",
      "\r46.4%",
      "\r46.4%",
      "\r46.5%",
      "\r46.6%",
      "\r46.7%",
      "\r46.8%",
      "\r46.9%",
      "\r46.9%",
      "\r47.0%",
      "\r47.1%",
      "\r47.2%",
      "\r47.3%",
      "\r47.4%",
      "\r47.4%",
      "\r47.5%",
      "\r47.6%",
      "\r47.7%",
      "\r47.8%",
      "\r47.9%",
      "\r47.9%",
      "\r48.0%",
      "\r48.1%",
      "\r48.2%",
      "\r48.3%",
      "\r48.3%",
      "\r48.4%",
      "\r48.5%",
      "\r48.6%",
      "\r48.7%",
      "\r48.8%",
      "\r48.8%",
      "\r48.9%",
      "\r49.0%",
      "\r49.1%",
      "\r49.2%",
      "\r49.3%",
      "\r49.3%",
      "\r49.4%",
      "\r49.5%",
      "\r49.6%",
      "\r49.7%",
      "\r49.8%",
      "\r49.8%",
      "\r49.9%",
      "\r50.0%",
      "\r50.1%",
      "\r50.2%",
      "\r50.2%",
      "\r50.3%",
      "\r50.4%",
      "\r50.5%",
      "\r50.6%",
      "\r50.7%",
      "\r50.7%",
      "\r50.8%",
      "\r50.9%",
      "\r51.0%",
      "\r51.1%",
      "\r51.2%",
      "\r51.2%",
      "\r51.3%",
      "\r51.4%",
      "\r51.5%",
      "\r51.6%",
      "\r51.7%",
      "\r51.7%",
      "\r51.8%",
      "\r51.9%",
      "\r52.0%",
      "\r52.1%",
      "\r52.1%",
      "\r52.2%",
      "\r52.3%",
      "\r52.4%",
      "\r52.5%",
      "\r52.6%",
      "\r52.6%",
      "\r52.7%",
      "\r52.8%",
      "\r52.9%",
      "\r53.0%",
      "\r53.1%",
      "\r53.1%",
      "\r53.2%",
      "\r53.3%",
      "\r53.4%",
      "\r53.5%",
      "\r53.6%",
      "\r53.6%",
      "\r53.7%",
      "\r53.8%",
      "\r53.9%",
      "\r54.0%",
      "\r54.0%",
      "\r54.1%",
      "\r54.2%",
      "\r54.3%",
      "\r54.4%",
      "\r54.5%",
      "\r54.5%",
      "\r54.6%",
      "\r54.7%",
      "\r54.8%",
      "\r54.9%",
      "\r55.0%",
      "\r55.0%",
      "\r55.1%",
      "\r55.2%",
      "\r55.3%",
      "\r55.4%",
      "\r55.5%",
      "\r55.5%",
      "\r55.6%",
      "\r55.7%",
      "\r55.8%",
      "\r55.9%",
      "\r55.9%",
      "\r56.0%",
      "\r56.1%",
      "\r56.2%",
      "\r56.3%",
      "\r56.4%",
      "\r56.4%",
      "\r56.5%",
      "\r56.6%",
      "\r56.7%",
      "\r56.8%",
      "\r56.9%",
      "\r56.9%",
      "\r57.0%",
      "\r57.1%",
      "\r57.2%",
      "\r57.3%",
      "\r57.4%",
      "\r57.4%",
      "\r57.5%",
      "\r57.6%",
      "\r57.7%",
      "\r57.8%",
      "\r57.9%",
      "\r57.9%",
      "\r58.0%",
      "\r58.1%",
      "\r58.2%",
      "\r58.3%",
      "\r58.3%",
      "\r58.4%",
      "\r58.5%",
      "\r58.6%",
      "\r58.7%",
      "\r58.8%",
      "\r58.8%",
      "\r58.9%",
      "\r59.0%",
      "\r59.1%",
      "\r59.2%",
      "\r59.3%",
      "\r59.3%",
      "\r59.4%",
      "\r59.5%",
      "\r59.6%",
      "\r59.7%",
      "\r59.8%",
      "\r59.8%",
      "\r59.9%",
      "\r60.0%",
      "\r60.1%",
      "\r60.2%",
      "\r60.2%",
      "\r60.3%",
      "\r60.4%",
      "\r60.5%",
      "\r60.6%",
      "\r60.7%",
      "\r60.7%",
      "\r60.8%",
      "\r60.9%",
      "\r61.0%",
      "\r61.1%",
      "\r61.2%",
      "\r61.2%",
      "\r61.3%",
      "\r61.4%",
      "\r61.5%",
      "\r61.6%",
      "\r61.7%",
      "\r61.7%",
      "\r61.8%",
      "\r61.9%",
      "\r62.0%",
      "\r62.1%",
      "\r62.1%",
      "\r62.2%",
      "\r62.3%",
      "\r62.4%",
      "\r62.5%",
      "\r62.6%",
      "\r62.6%",
      "\r62.7%",
      "\r62.8%",
      "\r62.9%",
      "\r63.0%",
      "\r63.1%",
      "\r63.1%",
      "\r63.2%",
      "\r63.3%",
      "\r63.4%",
      "\r63.5%",
      "\r63.6%",
      "\r63.6%",
      "\r63.7%",
      "\r63.8%",
      "\r63.9%",
      "\r64.0%",
      "\r64.0%",
      "\r64.1%",
      "\r64.2%",
      "\r64.3%",
      "\r64.4%",
      "\r64.5%",
      "\r64.5%",
      "\r64.6%",
      "\r64.7%",
      "\r64.8%",
      "\r64.9%",
      "\r65.0%",
      "\r65.0%",
      "\r65.1%",
      "\r65.2%",
      "\r65.3%",
      "\r65.4%",
      "\r65.5%",
      "\r65.5%",
      "\r65.6%",
      "\r65.7%",
      "\r65.8%",
      "\r65.9%",
      "\r65.9%",
      "\r66.0%",
      "\r66.1%",
      "\r66.2%",
      "\r66.3%",
      "\r66.4%",
      "\r66.4%",
      "\r66.5%",
      "\r66.6%",
      "\r66.7%",
      "\r66.8%",
      "\r66.9%",
      "\r66.9%",
      "\r67.0%",
      "\r67.1%",
      "\r67.2%",
      "\r67.3%",
      "\r67.4%",
      "\r67.4%",
      "\r67.5%",
      "\r67.6%",
      "\r67.7%",
      "\r67.8%",
      "\r67.9%",
      "\r67.9%",
      "\r68.0%",
      "\r68.1%",
      "\r68.2%",
      "\r68.3%",
      "\r68.3%",
      "\r68.4%",
      "\r68.5%",
      "\r68.6%",
      "\r68.7%",
      "\r68.8%",
      "\r68.8%",
      "\r68.9%",
      "\r69.0%",
      "\r69.1%",
      "\r69.2%",
      "\r69.3%",
      "\r69.3%",
      "\r69.4%",
      "\r69.5%",
      "\r69.6%",
      "\r69.7%",
      "\r69.8%",
      "\r69.8%",
      "\r69.9%",
      "\r70.0%",
      "\r70.1%",
      "\r70.2%",
      "\r70.2%",
      "\r70.3%",
      "\r70.4%",
      "\r70.5%",
      "\r70.6%",
      "\r70.7%",
      "\r70.7%",
      "\r70.8%",
      "\r70.9%",
      "\r71.0%",
      "\r71.1%",
      "\r71.2%",
      "\r71.2%",
      "\r71.3%",
      "\r71.4%",
      "\r71.5%",
      "\r71.6%",
      "\r71.7%",
      "\r71.7%",
      "\r71.8%",
      "\r71.9%",
      "\r72.0%",
      "\r72.1%",
      "\r72.1%",
      "\r72.2%",
      "\r72.3%",
      "\r72.4%",
      "\r72.5%",
      "\r72.6%",
      "\r72.6%",
      "\r72.7%",
      "\r72.8%",
      "\r72.9%",
      "\r73.0%",
      "\r73.1%",
      "\r73.1%",
      "\r73.2%",
      "\r73.3%",
      "\r73.4%",
      "\r73.5%",
      "\r73.6%",
      "\r73.6%",
      "\r73.7%",
      "\r73.8%",
      "\r73.9%",
      "\r74.0%",
      "\r74.0%",
      "\r74.1%",
      "\r74.2%",
      "\r74.3%",
      "\r74.4%",
      "\r74.5%",
      "\r74.5%",
      "\r74.6%",
      "\r74.7%",
      "\r74.8%",
      "\r74.9%",
      "\r75.0%",
      "\r75.0%",
      "\r75.1%",
      "\r75.2%",
      "\r75.3%",
      "\r75.4%",
      "\r75.5%",
      "\r75.5%",
      "\r75.6%",
      "\r75.7%",
      "\r75.8%",
      "\r75.9%",
      "\r75.9%",
      "\r76.0%",
      "\r76.1%",
      "\r76.2%",
      "\r76.3%",
      "\r76.4%",
      "\r76.4%",
      "\r76.5%",
      "\r76.6%",
      "\r76.7%",
      "\r76.8%",
      "\r76.9%",
      "\r76.9%",
      "\r77.0%",
      "\r77.1%",
      "\r77.2%",
      "\r77.3%",
      "\r77.4%",
      "\r77.4%",
      "\r77.5%",
      "\r77.6%",
      "\r77.7%",
      "\r77.8%",
      "\r77.9%",
      "\r77.9%",
      "\r78.0%",
      "\r78.1%",
      "\r78.2%",
      "\r78.3%",
      "\r78.3%",
      "\r78.4%",
      "\r78.5%",
      "\r78.6%",
      "\r78.7%",
      "\r78.8%",
      "\r78.8%",
      "\r78.9%",
      "\r79.0%",
      "\r79.1%",
      "\r79.2%",
      "\r79.3%",
      "\r79.3%",
      "\r79.4%",
      "\r79.5%",
      "\r79.6%",
      "\r79.7%",
      "\r79.8%",
      "\r79.8%",
      "\r79.9%",
      "\r80.0%",
      "\r80.1%",
      "\r80.2%",
      "\r80.2%",
      "\r80.3%",
      "\r80.4%",
      "\r80.5%",
      "\r80.6%",
      "\r80.7%",
      "\r80.7%",
      "\r80.8%",
      "\r80.9%",
      "\r81.0%",
      "\r81.1%",
      "\r81.2%",
      "\r81.2%",
      "\r81.3%",
      "\r81.4%",
      "\r81.5%",
      "\r81.6%",
      "\r81.7%",
      "\r81.7%",
      "\r81.8%",
      "\r81.9%",
      "\r82.0%",
      "\r82.1%",
      "\r82.1%",
      "\r82.2%",
      "\r82.3%",
      "\r82.4%",
      "\r82.5%",
      "\r82.6%",
      "\r82.6%",
      "\r82.7%",
      "\r82.8%",
      "\r82.9%",
      "\r83.0%",
      "\r83.1%",
      "\r83.1%",
      "\r83.2%",
      "\r83.3%",
      "\r83.4%",
      "\r83.5%",
      "\r83.6%",
      "\r83.6%",
      "\r83.7%",
      "\r83.8%",
      "\r83.9%",
      "\r84.0%",
      "\r84.0%",
      "\r84.1%",
      "\r84.2%",
      "\r84.3%",
      "\r84.4%",
      "\r84.5%",
      "\r84.5%",
      "\r84.6%",
      "\r84.7%",
      "\r84.8%",
      "\r84.9%",
      "\r85.0%",
      "\r85.0%",
      "\r85.1%",
      "\r85.2%",
      "\r85.3%",
      "\r85.4%",
      "\r85.5%",
      "\r85.5%",
      "\r85.6%",
      "\r85.7%",
      "\r85.8%",
      "\r85.9%",
      "\r85.9%",
      "\r86.0%",
      "\r86.1%",
      "\r86.2%",
      "\r86.3%",
      "\r86.4%",
      "\r86.4%",
      "\r86.5%",
      "\r86.6%",
      "\r86.7%",
      "\r86.8%",
      "\r86.9%",
      "\r86.9%",
      "\r87.0%",
      "\r87.1%",
      "\r87.2%",
      "\r87.3%",
      "\r87.4%",
      "\r87.4%",
      "\r87.5%",
      "\r87.6%",
      "\r87.7%",
      "\r87.8%",
      "\r87.9%",
      "\r87.9%",
      "\r88.0%",
      "\r88.1%",
      "\r88.2%",
      "\r88.3%",
      "\r88.3%",
      "\r88.4%",
      "\r88.5%",
      "\r88.6%",
      "\r88.7%",
      "\r88.8%",
      "\r88.8%",
      "\r88.9%",
      "\r89.0%",
      "\r89.1%",
      "\r89.2%",
      "\r89.3%",
      "\r89.3%",
      "\r89.4%",
      "\r89.5%",
      "\r89.6%",
      "\r89.7%",
      "\r89.8%",
      "\r89.8%",
      "\r89.9%",
      "\r90.0%",
      "\r90.1%",
      "\r90.2%",
      "\r90.2%",
      "\r90.3%",
      "\r90.4%",
      "\r90.5%",
      "\r90.6%",
      "\r90.7%",
      "\r90.7%",
      "\r90.8%",
      "\r90.9%",
      "\r91.0%",
      "\r91.1%",
      "\r91.2%",
      "\r91.2%",
      "\r91.3%",
      "\r91.4%",
      "\r91.5%",
      "\r91.6%",
      "\r91.7%",
      "\r91.7%",
      "\r91.8%",
      "\r91.9%",
      "\r92.0%",
      "\r92.1%",
      "\r92.1%",
      "\r92.2%",
      "\r92.3%",
      "\r92.4%",
      "\r92.5%",
      "\r92.6%",
      "\r92.6%",
      "\r92.7%",
      "\r92.8%",
      "\r92.9%",
      "\r93.0%",
      "\r93.1%",
      "\r93.1%",
      "\r93.2%",
      "\r93.3%",
      "\r93.4%",
      "\r93.5%",
      "\r93.6%",
      "\r93.6%",
      "\r93.7%",
      "\r93.8%",
      "\r93.9%",
      "\r94.0%",
      "\r94.0%",
      "\r94.1%",
      "\r94.2%",
      "\r94.3%",
      "\r94.4%",
      "\r94.5%",
      "\r94.5%",
      "\r94.6%",
      "\r94.7%",
      "\r94.8%",
      "\r94.9%",
      "\r95.0%",
      "\r95.0%",
      "\r95.1%",
      "\r95.2%",
      "\r95.3%",
      "\r95.4%",
      "\r95.5%",
      "\r95.5%",
      "\r95.6%",
      "\r95.7%",
      "\r95.8%",
      "\r95.9%",
      "\r95.9%",
      "\r96.0%",
      "\r96.1%",
      "\r96.2%",
      "\r96.3%",
      "\r96.4%",
      "\r96.4%",
      "\r96.5%",
      "\r96.6%",
      "\r96.7%",
      "\r96.8%",
      "\r96.9%",
      "\r96.9%",
      "\r97.0%",
      "\r97.1%",
      "\r97.2%",
      "\r97.3%",
      "\r97.4%",
      "\r97.4%",
      "\r97.5%",
      "\r97.6%",
      "\r97.7%",
      "\r97.8%",
      "\r97.9%",
      "\r97.9%",
      "\r98.0%",
      "\r98.1%",
      "\r98.2%",
      "\r98.3%",
      "\r98.3%",
      "\r98.4%",
      "\r98.5%",
      "\r98.6%",
      "\r98.7%",
      "\r98.8%",
      "\r98.8%",
      "\r98.9%",
      "\r99.0%",
      "\r99.1%",
      "\r99.2%",
      "\r99.3%",
      "\r99.3%",
      "\r99.4%",
      "\r99.5%",
      "\r99.6%",
      "\r99.7%",
      "\r99.8%",
      "\r99.8%",
      "\r99.9%",
      "\r100.0%",
      "\r100.1%",
      "\r0.0%",
      "\r28.4%",
      "\r56.7%",
      "\r85.1%",
      "\r113.5%",
      "\r0.0%",
      "\r0.5%",
      "\r1.0%",
      "\r1.5%",
      "\r2.0%",
      "\r2.5%",
      "\r3.0%",
      "\r3.5%",
      "\r4.0%",
      "\r4.5%",
      "\r5.0%",
      "\r5.5%",
      "\r6.0%",
      "\r6.5%",
      "\r7.0%",
      "\r7.5%",
      "\r7.9%",
      "\r8.4%",
      "\r8.9%",
      "\r9.4%",
      "\r9.9%",
      "\r10.4%",
      "\r10.9%",
      "\r11.4%",
      "\r11.9%",
      "\r12.4%",
      "\r12.9%",
      "\r13.4%",
      "\r13.9%",
      "\r14.4%",
      "\r14.9%",
      "\r15.4%",
      "\r15.9%",
      "\r16.4%",
      "\r16.9%",
      "\r17.4%",
      "\r17.9%",
      "\r18.4%",
      "\r18.9%",
      "\r19.4%",
      "\r19.9%",
      "\r20.4%",
      "\r20.9%",
      "\r21.4%",
      "\r21.9%",
      "\r22.4%",
      "\r22.9%",
      "\r23.4%",
      "\r23.8%",
      "\r24.3%",
      "\r24.8%",
      "\r25.3%",
      "\r25.8%",
      "\r26.3%",
      "\r26.8%",
      "\r27.3%",
      "\r27.8%",
      "\r28.3%",
      "\r28.8%",
      "\r29.3%",
      "\r29.8%",
      "\r30.3%",
      "\r30.8%",
      "\r31.3%",
      "\r31.8%",
      "\r32.3%",
      "\r32.8%",
      "\r33.3%",
      "\r33.8%",
      "\r34.3%",
      "\r34.8%",
      "\r35.3%",
      "\r35.8%",
      "\r36.3%",
      "\r36.8%",
      "\r37.3%",
      "\r37.8%",
      "\r38.3%",
      "\r38.8%",
      "\r39.2%",
      "\r39.7%",
      "\r40.2%",
      "\r40.7%",
      "\r41.2%",
      "\r41.7%",
      "\r42.2%",
      "\r42.7%",
      "\r43.2%",
      "\r43.7%",
      "\r44.2%",
      "\r44.7%",
      "\r45.2%",
      "\r45.7%",
      "\r46.2%",
      "\r46.7%",
      "\r47.2%",
      "\r47.7%",
      "\r48.2%",
      "\r48.7%",
      "\r49.2%",
      "\r49.7%",
      "\r50.2%",
      "\r50.7%",
      "\r51.2%",
      "\r51.7%",
      "\r52.2%",
      "\r52.7%",
      "\r53.2%",
      "\r53.7%",
      "\r54.2%",
      "\r54.7%",
      "\r55.1%",
      "\r55.6%",
      "\r56.1%",
      "\r56.6%",
      "\r57.1%",
      "\r57.6%",
      "\r58.1%",
      "\r58.6%",
      "\r59.1%",
      "\r59.6%",
      "\r60.1%",
      "\r60.6%",
      "\r61.1%",
      "\r61.6%",
      "\r62.1%",
      "\r62.6%",
      "\r63.1%",
      "\r63.6%",
      "\r64.1%",
      "\r64.6%",
      "\r65.1%",
      "\r65.6%",
      "\r66.1%",
      "\r66.6%",
      "\r67.1%",
      "\r67.6%",
      "\r68.1%",
      "\r68.6%",
      "\r69.1%",
      "\r69.6%",
      "\r70.1%",
      "\r70.5%",
      "\r71.0%",
      "\r71.5%",
      "\r72.0%",
      "\r72.5%",
      "\r73.0%",
      "\r73.5%",
      "\r74.0%",
      "\r74.5%",
      "\r75.0%",
      "\r75.5%",
      "\r76.0%",
      "\r76.5%",
      "\r77.0%",
      "\r77.5%",
      "\r78.0%",
      "\r78.5%",
      "\r79.0%",
      "\r79.5%",
      "\r80.0%",
      "\r80.5%",
      "\r81.0%",
      "\r81.5%",
      "\r82.0%",
      "\r82.5%",
      "\r83.0%",
      "\r83.5%",
      "\r84.0%",
      "\r84.5%",
      "\r85.0%",
      "\r85.5%",
      "\r86.0%",
      "\r86.4%",
      "\r86.9%",
      "\r87.4%",
      "\r87.9%",
      "\r88.4%",
      "\r88.9%",
      "\r89.4%",
      "\r89.9%",
      "\r90.4%",
      "\r90.9%",
      "\r91.4%",
      "\r91.9%",
      "\r92.4%",
      "\r92.9%",
      "\r93.4%",
      "\r93.9%",
      "\r94.4%",
      "\r94.9%",
      "\r95.4%",
      "\r95.9%",
      "\r96.4%",
      "\r96.9%",
      "\r97.4%",
      "\r97.9%",
      "\r98.4%",
      "\r98.9%",
      "\r99.4%",
      "\r99.9%",
      "\r100.4%",
      "\r0.0%",
      "\r180.4%"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K5cYwBL2fISH",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "dataset_len = len(mnist)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QPrTXSnZfISN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "ba7c85c7-53ff-466f-bb4b-d85a18921b84",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1575228639813,
     "user_tz": -60,
     "elapsed": 12282,
     "user": {
      "displayName": "Sergio Garcia",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64",
      "userId": "16139820604268433723"
     }
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "dataset_len * 0.95"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "57000.0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B1BwFJY_fISU",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist, [57000, dataset_len - 57000])"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b5yH0O1kfISY",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_train,\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fNNQ25Z-fISe",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "adam = torch.optim.Adam(autoencoder.parameters(), lr=0.001)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AEwsot_KfISi",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def train(model, dataloader, criterion, optimizer, epoch):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        images = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed = model(images)\n",
    "        loss = criterion(reconstructed, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss.item()))"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CXQlTiq2fISm",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "4c8762a1-882e-4092-ae1d-d01a899bc9c0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1575228794730,
     "user_tz": -60,
     "elapsed": 91626,
     "user": {
      "displayName": "Sergio Garcia",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64",
      "userId": "16139820604268433723"
     }
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "for epoch in range(5):\n",
    "    train(autoencoder, train_dataloader, mse, adam, epoch)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1, 1] loss: 1.034\n",
      "[1, 101] loss: 0.484\n",
      "[1, 201] loss: 0.363\n",
      "[1, 301] loss: 0.354\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ea6621388a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-9c86e222147b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mreconstructed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\worldsensing\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\worldsensing\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3OKrrQKRfISs",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "mnist_test = torchvision.datasets.MNIST('mnist_dataset', train=False, transform=transform)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DQh4_KZ8h5Aj",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "reconstructed = autoencoder(mnist_test[0][0].to(device).unsqueeze(0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jmq0GFneiCDo",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dZnZDQXqiGgv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "outputId": "6ad1ca25-3c71-4b48-b64f-e49ded890343",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1575228917871,
     "user_tz": -60,
     "elapsed": 1131,
     "user": {
      "displayName": "Sergio Garcia",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDTm-mE3fT-h7wpEZpGtZu9jSK24Hqhb2nqpKiyysE=s64",
      "userId": "16139820604268433723"
     }
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(mnist_test[0][0][0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(reconstructed[0][0].detach().cpu().numpy(), cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pyEnlw7JiJ-X",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}